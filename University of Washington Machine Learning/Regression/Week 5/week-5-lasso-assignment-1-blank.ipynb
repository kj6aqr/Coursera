{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: Feature Selection and LASSO (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using GraphLab Create, though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up graphlab create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales = graphlab.SFrame('kc_house_data.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we consider features that are some transformations of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "\n",
    "# In the dataset, 'floors' was defined with type string, \n",
    "# so we'll convert them to float, before creating a new feature.\n",
    "sales['floors'] = sales['floors'].astype(float) \n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn regression weights with L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fit a model with all the features available, plus the features we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying L1 penalty requires adding an extra parameter (`l1_penalty`) to the linear regression call in GraphLab Create. (Other tools may have separate implementations of LASSO.)  Note that it's important to set `l2_penalty=0` to ensure we don't introduce an additional L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Linear regression:</pre>"
      ],
      "text/plain": [
       "Linear regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 21613</pre>"
      ],
      "text/plain": [
       "Number of examples          : 21613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of features          : 17</pre>"
      ],
      "text/plain": [
       "Number of features          : 17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 17</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 18</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting Accelerated Gradient (FISTA)</pre>"
      ],
      "text/plain": [
       "Starting Accelerated Gradient (FISTA)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Tuning step size. First iteration could take longer than subsequent iterations.</pre>"
      ],
      "text/plain": [
       "Tuning step size. First iteration could take longer than subsequent iterations."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 2        | 0.000002  | 0.512829     | 6962915.603493     | 426631.749026 |</pre>"
      ],
      "text/plain": [
       "| 1         | 2        | 0.000002  | 0.512829     | 6962915.603493     | 426631.749026 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 3        | 0.000002  | 0.556499     | 6843144.200219     | 392488.929838 |</pre>"
      ],
      "text/plain": [
       "| 2         | 3        | 0.000002  | 0.556499     | 6843144.200219     | 392488.929838 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 4        | 0.000002  | 0.601692     | 6831900.032123     | 385340.166783 |</pre>"
      ],
      "text/plain": [
       "| 3         | 4        | 0.000002  | 0.601692     | 6831900.032123     | 385340.166783 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 5        | 0.000002  | 0.646960     | 6847166.848958     | 384842.383767 |</pre>"
      ],
      "text/plain": [
       "| 4         | 5        | 0.000002  | 0.646960     | 6847166.848958     | 384842.383767 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 6        | 0.000002  | 0.689469     | 6869667.895833     | 385998.458623 |</pre>"
      ],
      "text/plain": [
       "| 5         | 6        | 0.000002  | 0.689469     | 6869667.895833     | 385998.458623 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 7        | 0.000002  | 0.734492     | 6847177.773672     | 380824.455891 |</pre>"
      ],
      "text/plain": [
       "| 6         | 7        | 0.000002  | 0.734492     | 6847177.773672     | 380824.455891 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>TERMINATED: Iteration limit reached.</pre>"
      ],
      "text/plain": [
       "TERMINATED: Iteration limit reached."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>This model may not be optimal. To improve it, consider increasing `max_iterations`.</pre>"
      ],
      "text/plain": [
       "This model may not be optimal. To improve it, consider increasing `max_iterations`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_all = graphlab.linear_regression.create(sales, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=1e10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what features had non-zero weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+---------------+--------+\n",
      "|       name       | index |     value     | stderr |\n",
      "+------------------+-------+---------------+--------+\n",
      "|   (intercept)    |  None |  274873.05595 |  None  |\n",
      "|     bedrooms     |  None |      0.0      |  None  |\n",
      "| bedrooms_square  |  None |      0.0      |  None  |\n",
      "|    bathrooms     |  None | 8468.53108691 |  None  |\n",
      "|   sqft_living    |  None | 24.4207209824 |  None  |\n",
      "| sqft_living_sqrt |  None | 350.060553386 |  None  |\n",
      "|     sqft_lot     |  None |      0.0      |  None  |\n",
      "|  sqft_lot_sqrt   |  None |      0.0      |  None  |\n",
      "|      floors      |  None |      0.0      |  None  |\n",
      "|  floors_square   |  None |      0.0      |  None  |\n",
      "|    waterfront    |  None |      0.0      |  None  |\n",
      "|       view       |  None |      0.0      |  None  |\n",
      "|    condition     |  None |      0.0      |  None  |\n",
      "|      grade       |  None | 842.068034898 |  None  |\n",
      "|    sqft_above    |  None | 20.0247224171 |  None  |\n",
      "|  sqft_basement   |  None |      0.0      |  None  |\n",
      "|     yr_built     |  None |      0.0      |  None  |\n",
      "|   yr_renovated   |  None |      0.0      |  None  |\n",
      "+------------------+-------+---------------+--------+\n",
      "[18 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_all[\"coefficients\"].print_rows(num_rows=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
    "\n",
    "***QUIZ QUESTION***:\n",
    "According to this list of weights, which of the features have been chosen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
    "* Split our sales data into 2 sets: training and test\n",
    "* Further split our training data into two sets: train, validation\n",
    "\n",
    "Be *very* careful that you use seed = 1 to ensure you get the same answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(training_and_validation, testing) = sales.random_split(.9,seed=1) # initial train/test split\n",
    "(training, validation) = training_and_validation.random_split(0.5, seed=1) # split training into train and validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10.0, 625766285142461.2), (31.622776601683793, 625766285362395.2), (100.0, 625766286057887.0), (316.22776601683796, 625766288257224.9), (1000.0, 625766295212186.0), (3162.2776601683795, 625766317206077.8), (10000.0, 625766386760661.5), (31622.776601683792, 625766606749281.4), (100000.0, 625767302791633.4), (316227.76601683791, 625769507643885.1), (1000000.0, 625776517727025.8), (3162277.6601683795, 625799062845466.9), (10000000.0, 625883719085424.5)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x115ac76d0>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAETCAYAAADNpUayAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCSGlNxFRGLo/wEgHKP0tFC/CAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117e47950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rsses = []\n",
    "plot_x = []\n",
    "plot_y = []\n",
    "for i in np.logspace(1, 7, num=13):\n",
    "    model = graphlab.linear_regression.create(training, target='price', features=all_features, verbose=False,\n",
    "                                              validation_set=None, l2_penalty=0, l1_penalty=i)\n",
    "    predictions = model.predict(validation)\n",
    "    rss = sum((validation[\"price\"]-predictions)**2)\n",
    "    rsses.append((i,rss))\n",
    "    plot_x.append(i)\n",
    "    plot_y.append(rss)\n",
    "print rsses\n",
    "plt.plot(plot_x,plot_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTIONS ***\n",
    "1. What was the best value for the `l1_penalty`?\n",
    "2. What is the RSS on TEST data of the model with the best `l1_penalty`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10.0, 625766285142461.2)\n",
      "156983602.382\n"
     ]
    }
   ],
   "source": [
    "best_l1=min(rsses, key = lambda t: t[1])\n",
    "print best_l1\n",
    "\n",
    "model = graphlab.linear_regression.create(training, target='price', features=all_features, verbose=False,\n",
    "                                              validation_set=None, l2_penalty=0, l1_penalty=best_l1[0])\n",
    "predictions = model.predict(testing)\n",
    "rss = sum((testing[\"price\"]-predictions)**2)\n",
    "print rss/1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "Also, using this value of L1 penalty, how many nonzero weights do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+------------------+--------+\n",
      "|       name       | index |      value       | stderr |\n",
      "+------------------+-------+------------------+--------+\n",
      "|   (intercept)    |  None |   21251.456037   |  None  |\n",
      "|     bedrooms     |  None |  8023.23712748   |  None  |\n",
      "| bedrooms_square  |  None |  2315.12367247   |  None  |\n",
      "|    bathrooms     |  None |   23478.596342   |  None  |\n",
      "|   sqft_living    |  None |  35.8035138152   |  None  |\n",
      "| sqft_living_sqrt |  None |  1081.33507648   |  None  |\n",
      "|     sqft_lot     |  None | -0.0262827717894 |  None  |\n",
      "|  sqft_lot_sqrt   |  None |  145.436647604   |  None  |\n",
      "|      floors      |  None |   20447.520062   |  None  |\n",
      "|  floors_square   |  None |   11514.116277   |  None  |\n",
      "|    waterfront    |  None |  595536.451305   |  None  |\n",
      "|       view       |  None |  95362.3454158   |  None  |\n",
      "|    condition     |  None |  7063.68121335   |  None  |\n",
      "|      grade       |  None |   6191.241929    |  None  |\n",
      "|    sqft_above    |  None |  39.2366857593   |  None  |\n",
      "|  sqft_basement   |  None |   116.06067067   |  None  |\n",
      "|     yr_built     |  None |  10.5801397605   |  None  |\n",
      "|   yr_renovated   |  None |  64.8466733814   |  None  |\n",
      "+------------------+-------+------------------+--------+\n",
      "[18 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=graphlab.linear_regression.create(validation, target='price', features=all_features, verbose=False,\n",
    "                                              validation_set=None, l2_penalty=0, l1_penalty=best_l1[0])\n",
    "model[\"coefficients\"].print_rows(num_rows=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
    "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "Let's define a wide range of possible `l1_penalty_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.logspace(8, 10, num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement a loop that search through this space of possible `l1_penalty` values:\n",
    "\n",
    "* For `l1_penalty` in `np.logspace(8, 10, num=20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Extract the weights of the model and count the number of nonzeros. Save the number of nonzeros to a list.\n",
    "        * *Hint: `model['coefficients']['value']` gives you an SArray with the parameters you learned.  If you call the method `.nnz()` on it, you will find the number of non-zero parameters!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100000000.0, 18), (127427498.57031322, 18), (162377673.91887242, 18), (206913808.11147901, 18), (263665089.87303555, 17), (335981828.62837881, 17), (428133239.8719396, 17), (545559478.11685145, 17), (695192796.17755914, 17), (885866790.41008317, 16), (1128837891.6846883, 15), (1438449888.2876658, 15), (1832980710.8324375, 13), (2335721469.0901213, 12), (2976351441.6313133, 10), (3792690190.7322536, 6), (4832930238.5717525, 5), (6158482110.6602545, 3), (7847599703.5146227, 1), (10000000000.0, 1)]\n"
     ]
    }
   ],
   "source": [
    "nonzeroes=[]\n",
    "for l1_penalty in l1_penalty_values:\n",
    "    model = graphlab.linear_regression.create(training, target='price', features=all_features, verbose=False,\n",
    "                                              validation_set=None, l2_penalty=0, l1_penalty=l1_penalty)\n",
    "    nonzeroes.append((l1_penalty,model['coefficients']['value'].nnz()))\n",
    "print nonzeroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of this large range, we want to find the two ends of our desired narrow range of `l1_penalty`.  At one end, we will have `l1_penalty` values that have too few non-zeros, and at the other end, we will have an `l1_penalty` that has too many non-zeros.  \n",
    "\n",
    "More formally, find:\n",
    "* The largest `l1_penalty` that has more non-zeros than `max_nonzero` (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_min` (we will use it later)\n",
    "* The smallest `l1_penalty` that has fewer non-zeros than `max_nonzero` (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_max` (we will use it later)\n",
    "\n",
    "\n",
    "*Hint: there are many ways to do this, e.g.:*\n",
    "* Programmatically within the loop above\n",
    "* Creating a list with the number of non-zeros for each value of `l1_penalty` and inspecting it to find the appropriate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty_min = 2976351441.6313133\n",
    "l1_penalty_max = 3792690190.7322536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "\n",
    "What values did you find for `l1_penalty_min` and`l1_penalty_max`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "\n",
    "We will now explore the narrow region of `l1_penalty` values we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "Find the model that the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzero`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3448968612.1634369, 1046937488751713.6, 7), (3491933809.484539, 1051147625612863.0, 7), (3534899006.8056412, 1055992735342999.2, 7), (3577864204.1267428, 1060799531763290.2, 7)]\n"
     ]
    }
   ],
   "source": [
    "penalties=[]\n",
    "for l1_penalty in np.linspace(l1_penalty_min,l1_penalty_max,20):\n",
    "    model = graphlab.linear_regression.create(training, target='price', features=all_features, verbose=False,\n",
    "                                              validation_set=None, l2_penalty=0, l1_penalty=l1_penalty)\n",
    "    nonzero = model['coefficients']['value'].nnz()\n",
    "    if nonzero == max_nonzeros:\n",
    "        predictions = model.predict(validation)\n",
    "        rss = sum((validation[\"price\"]-predictions)**2)\n",
    "        penalties.append((l1_penalty,rss,nonzero))\n",
    "print penalties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`?\n",
    "2. What features in this model have non-zero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3448968612.1634369, 1046937488751713.6, 7)\n"
     ]
    }
   ],
   "source": [
    "best_l1 = min(penalties, key = lambda t: t[1])\n",
    "print best_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+---------------+--------+\n",
      "|       name       | index |     value     | stderr |\n",
      "+------------------+-------+---------------+--------+\n",
      "|   (intercept)    |  None | 222253.192544 |  None  |\n",
      "|     bedrooms     |  None | 661.722717782 |  None  |\n",
      "| bedrooms_square  |  None |      0.0      |  None  |\n",
      "|    bathrooms     |  None | 15873.9572593 |  None  |\n",
      "|   sqft_living    |  None | 32.4102214513 |  None  |\n",
      "| sqft_living_sqrt |  None | 690.114773313 |  None  |\n",
      "|     sqft_lot     |  None |      0.0      |  None  |\n",
      "|  sqft_lot_sqrt   |  None |      0.0      |  None  |\n",
      "|      floors      |  None |      0.0      |  None  |\n",
      "|  floors_square   |  None |      0.0      |  None  |\n",
      "|    waterfront    |  None |      0.0      |  None  |\n",
      "|       view       |  None |      0.0      |  None  |\n",
      "|    condition     |  None |      0.0      |  None  |\n",
      "|      grade       |  None | 2899.42026975 |  None  |\n",
      "|    sqft_above    |  None | 30.0115753022 |  None  |\n",
      "|  sqft_basement   |  None |      0.0      |  None  |\n",
      "|     yr_built     |  None |      0.0      |  None  |\n",
      "|   yr_renovated   |  None |      0.0      |  None  |\n",
      "+------------------+-------+---------------+--------+\n",
      "[18 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = graphlab.linear_regression.create(training, target='price', features=all_features, verbose=False,\n",
    "                                              validation_set=None, l2_penalty=0, l1_penalty=best_l1[0])\n",
    "model['coefficients'].print_rows(num_rows=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
